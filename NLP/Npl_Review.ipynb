{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Npl_Review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI5JSyDguDl4"
      },
      "source": [
        "import nltk as nl\n",
        "import pandas as pd\n",
        "import numpy as nm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGBAS_bIv51S",
        "outputId": "fdba6c5c-37f9-4eb0-db67-b03b0781a8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dir(nl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AbstractLazySequence',\n",
              " 'AffixTagger',\n",
              " 'AlignedSent',\n",
              " 'Alignment',\n",
              " 'AnnotationTask',\n",
              " 'ApplicationExpression',\n",
              " 'Assignment',\n",
              " 'BigramAssocMeasures',\n",
              " 'BigramCollocationFinder',\n",
              " 'BigramTagger',\n",
              " 'BinaryMaxentFeatureEncoding',\n",
              " 'BlanklineTokenizer',\n",
              " 'BllipParser',\n",
              " 'BottomUpChartParser',\n",
              " 'BottomUpLeftCornerChartParser',\n",
              " 'BottomUpProbabilisticChartParser',\n",
              " 'Boxer',\n",
              " 'BrillTagger',\n",
              " 'BrillTaggerTrainer',\n",
              " 'CFG',\n",
              " 'CRFTagger',\n",
              " 'CfgReadingCommand',\n",
              " 'ChartParser',\n",
              " 'ChunkParserI',\n",
              " 'ChunkScore',\n",
              " 'ClassifierBasedPOSTagger',\n",
              " 'ClassifierBasedTagger',\n",
              " 'ClassifierI',\n",
              " 'ConcordanceIndex',\n",
              " 'ConditionalExponentialClassifier',\n",
              " 'ConditionalFreqDist',\n",
              " 'ConditionalProbDist',\n",
              " 'ConditionalProbDistI',\n",
              " 'ConfusionMatrix',\n",
              " 'ContextIndex',\n",
              " 'ContextTagger',\n",
              " 'ContingencyMeasures',\n",
              " 'CoreNLPDependencyParser',\n",
              " 'CoreNLPParser',\n",
              " 'Counter',\n",
              " 'CrossValidationProbDist',\n",
              " 'DRS',\n",
              " 'DecisionTreeClassifier',\n",
              " 'DefaultTagger',\n",
              " 'DependencyEvaluator',\n",
              " 'DependencyGrammar',\n",
              " 'DependencyGraph',\n",
              " 'DependencyProduction',\n",
              " 'DictionaryConditionalProbDist',\n",
              " 'DictionaryProbDist',\n",
              " 'DiscourseTester',\n",
              " 'DrtExpression',\n",
              " 'DrtGlueReadingCommand',\n",
              " 'ELEProbDist',\n",
              " 'EarleyChartParser',\n",
              " 'Expression',\n",
              " 'FStructure',\n",
              " 'FeatDict',\n",
              " 'FeatList',\n",
              " 'FeatStruct',\n",
              " 'FeatStructReader',\n",
              " 'Feature',\n",
              " 'FeatureBottomUpChartParser',\n",
              " 'FeatureBottomUpLeftCornerChartParser',\n",
              " 'FeatureChartParser',\n",
              " 'FeatureEarleyChartParser',\n",
              " 'FeatureIncrementalBottomUpChartParser',\n",
              " 'FeatureIncrementalBottomUpLeftCornerChartParser',\n",
              " 'FeatureIncrementalChartParser',\n",
              " 'FeatureIncrementalTopDownChartParser',\n",
              " 'FeatureTopDownChartParser',\n",
              " 'FreqDist',\n",
              " 'HTTPPasswordMgrWithDefaultRealm',\n",
              " 'HeldoutProbDist',\n",
              " 'HiddenMarkovModelTagger',\n",
              " 'HiddenMarkovModelTrainer',\n",
              " 'HunposTagger',\n",
              " 'IBMModel',\n",
              " 'IBMModel1',\n",
              " 'IBMModel2',\n",
              " 'IBMModel3',\n",
              " 'IBMModel4',\n",
              " 'IBMModel5',\n",
              " 'ISRIStemmer',\n",
              " 'ImmutableMultiParentedTree',\n",
              " 'ImmutableParentedTree',\n",
              " 'ImmutableProbabilisticMixIn',\n",
              " 'ImmutableProbabilisticTree',\n",
              " 'ImmutableTree',\n",
              " 'IncrementalBottomUpChartParser',\n",
              " 'IncrementalBottomUpLeftCornerChartParser',\n",
              " 'IncrementalChartParser',\n",
              " 'IncrementalLeftCornerChartParser',\n",
              " 'IncrementalTopDownChartParser',\n",
              " 'Index',\n",
              " 'InsideChartParser',\n",
              " 'JSONTaggedDecoder',\n",
              " 'JSONTaggedEncoder',\n",
              " 'KneserNeyProbDist',\n",
              " 'LancasterStemmer',\n",
              " 'LaplaceProbDist',\n",
              " 'LazyConcatenation',\n",
              " 'LazyEnumerate',\n",
              " 'LazyIteratorList',\n",
              " 'LazyMap',\n",
              " 'LazySubsequence',\n",
              " 'LazyZip',\n",
              " 'LeftCornerChartParser',\n",
              " 'LidstoneProbDist',\n",
              " 'LineTokenizer',\n",
              " 'LogicalExpressionException',\n",
              " 'LongestChartParser',\n",
              " 'MLEProbDist',\n",
              " 'MWETokenizer',\n",
              " 'Mace',\n",
              " 'MaceCommand',\n",
              " 'MaltParser',\n",
              " 'MaxentClassifier',\n",
              " 'Model',\n",
              " 'MultiClassifierI',\n",
              " 'MultiParentedTree',\n",
              " 'MutableProbDist',\n",
              " 'NaiveBayesClassifier',\n",
              " 'NaiveBayesDependencyScorer',\n",
              " 'NgramAssocMeasures',\n",
              " 'NgramTagger',\n",
              " 'NonprojectiveDependencyParser',\n",
              " 'Nonterminal',\n",
              " 'OrderedDict',\n",
              " 'PCFG',\n",
              " 'Paice',\n",
              " 'ParallelProverBuilder',\n",
              " 'ParallelProverBuilderCommand',\n",
              " 'ParentedTree',\n",
              " 'ParserI',\n",
              " 'PerceptronTagger',\n",
              " 'PhraseTable',\n",
              " 'PorterStemmer',\n",
              " 'PositiveNaiveBayesClassifier',\n",
              " 'ProbDistI',\n",
              " 'ProbabilisticDependencyGrammar',\n",
              " 'ProbabilisticMixIn',\n",
              " 'ProbabilisticNonprojectiveParser',\n",
              " 'ProbabilisticProduction',\n",
              " 'ProbabilisticProjectiveDependencyParser',\n",
              " 'ProbabilisticTree',\n",
              " 'Production',\n",
              " 'ProjectiveDependencyParser',\n",
              " 'Prover9',\n",
              " 'Prover9Command',\n",
              " 'ProxyBasicAuthHandler',\n",
              " 'ProxyDigestAuthHandler',\n",
              " 'ProxyHandler',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'QuadgramCollocationFinder',\n",
              " 'RSLPStemmer',\n",
              " 'RTEFeatureExtractor',\n",
              " 'RUS_PICKLE',\n",
              " 'RandomChartParser',\n",
              " 'RangeFeature',\n",
              " 'ReadingCommand',\n",
              " 'RecursiveDescentParser',\n",
              " 'RegexpChunkParser',\n",
              " 'RegexpParser',\n",
              " 'RegexpStemmer',\n",
              " 'RegexpTagger',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'ResolutionProver',\n",
              " 'ResolutionProverCommand',\n",
              " 'SExprTokenizer',\n",
              " 'SLASH',\n",
              " 'Senna',\n",
              " 'SennaChunkTagger',\n",
              " 'SennaNERTagger',\n",
              " 'SennaTagger',\n",
              " 'SequentialBackoffTagger',\n",
              " 'ShiftReduceParser',\n",
              " 'SimpleGoodTuringProbDist',\n",
              " 'SklearnClassifier',\n",
              " 'SlashFeature',\n",
              " 'SnowballStemmer',\n",
              " 'SpaceTokenizer',\n",
              " 'StackDecoder',\n",
              " 'StanfordNERTagger',\n",
              " 'StanfordPOSTagger',\n",
              " 'StanfordSegmenter',\n",
              " 'StanfordTagger',\n",
              " 'StemmerI',\n",
              " 'SteppingChartParser',\n",
              " 'SteppingRecursiveDescentParser',\n",
              " 'SteppingShiftReduceParser',\n",
              " 'TYPE',\n",
              " 'TabTokenizer',\n",
              " 'TableauProver',\n",
              " 'TableauProverCommand',\n",
              " 'TaggerI',\n",
              " 'TestGrammar',\n",
              " 'Text',\n",
              " 'TextCat',\n",
              " 'TextCollection',\n",
              " 'TextTilingTokenizer',\n",
              " 'TnT',\n",
              " 'TokenSearcher',\n",
              " 'ToktokTokenizer',\n",
              " 'TopDownChartParser',\n",
              " 'TransitionParser',\n",
              " 'Tree',\n",
              " 'TreebankWordTokenizer',\n",
              " 'Trie',\n",
              " 'TrigramAssocMeasures',\n",
              " 'TrigramCollocationFinder',\n",
              " 'TrigramTagger',\n",
              " 'TweetTokenizer',\n",
              " 'TypedMaxentFeatureEncoding',\n",
              " 'Undefined',\n",
              " 'UniformProbDist',\n",
              " 'UnigramTagger',\n",
              " 'UnsortedChartParser',\n",
              " 'Valuation',\n",
              " 'Variable',\n",
              " 'ViterbiParser',\n",
              " 'WekaClassifier',\n",
              " 'WhitespaceTokenizer',\n",
              " 'WittenBellProbDist',\n",
              " 'WordNetLemmatizer',\n",
              " 'WordPunctTokenizer',\n",
              " '__author__',\n",
              " '__author_email__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__classifiers__',\n",
              " '__copyright__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__keywords__',\n",
              " '__license__',\n",
              " '__loader__',\n",
              " '__longdescr__',\n",
              " '__maintainer__',\n",
              " '__maintainer_email__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__url__',\n",
              " '__version__',\n",
              " 'absolute_import',\n",
              " 'accuracy',\n",
              " 'add_logs',\n",
              " 'agreement',\n",
              " 'align',\n",
              " 'alignment_error_rate',\n",
              " 'aline',\n",
              " 'api',\n",
              " 'app',\n",
              " 'apply_features',\n",
              " 'approxrand',\n",
              " 'arity',\n",
              " 'association',\n",
              " 'bigrams',\n",
              " 'binary_distance',\n",
              " 'binary_search_file',\n",
              " 'binding_ops',\n",
              " 'bisect',\n",
              " 'blankline_tokenize',\n",
              " 'bleu',\n",
              " 'bleu_score',\n",
              " 'bllip',\n",
              " 'boolean_ops',\n",
              " 'boxer',\n",
              " 'bracket_parse',\n",
              " 'breadth_first',\n",
              " 'brill',\n",
              " 'brill_trainer',\n",
              " 'build_opener',\n",
              " 'call_megam',\n",
              " 'casual',\n",
              " 'casual_tokenize',\n",
              " 'ccg',\n",
              " 'chain',\n",
              " 'chart',\n",
              " 'chat',\n",
              " 'choose',\n",
              " 'chunk',\n",
              " 'class_types',\n",
              " 'classify',\n",
              " 'clause',\n",
              " 'clean_html',\n",
              " 'clean_url',\n",
              " 'cluster',\n",
              " 'collections',\n",
              " 'collocations',\n",
              " 'combinations',\n",
              " 'compat',\n",
              " 'config_java',\n",
              " 'config_megam',\n",
              " 'config_weka',\n",
              " 'conflicts',\n",
              " 'confusionmatrix',\n",
              " 'conllstr2tree',\n",
              " 'conlltags2tree',\n",
              " 'corenlp',\n",
              " 'corpus',\n",
              " 'crf',\n",
              " 'custom_distance',\n",
              " 'data',\n",
              " 'decisiontree',\n",
              " 'decorator',\n",
              " 'decorators',\n",
              " 'defaultdict',\n",
              " 'demo',\n",
              " 'dependencygraph',\n",
              " 'deque',\n",
              " 'discourse',\n",
              " 'distance',\n",
              " 'download',\n",
              " 'download_gui',\n",
              " 'download_shell',\n",
              " 'downloader',\n",
              " 'draw',\n",
              " 'drt',\n",
              " 'earleychart',\n",
              " 'edit_distance',\n",
              " 'elementtree_indent',\n",
              " 'entropy',\n",
              " 'equality_preds',\n",
              " 'evaluate',\n",
              " 'evaluate_sents',\n",
              " 'everygrams',\n",
              " 'extract_rels',\n",
              " 'extract_test_sentences',\n",
              " 'f_measure',\n",
              " 'featstruct',\n",
              " 'featurechart',\n",
              " 'filestring',\n",
              " 'find',\n",
              " 'flatten',\n",
              " 'fractional_presence',\n",
              " 'getproxies',\n",
              " 'ghd',\n",
              " 'glue',\n",
              " 'grammar',\n",
              " 'guess_encoding',\n",
              " 'help',\n",
              " 'hmm',\n",
              " 'hunpos',\n",
              " 'ibm1',\n",
              " 'ibm2',\n",
              " 'ibm3',\n",
              " 'ibm4',\n",
              " 'ibm5',\n",
              " 'ibm_model',\n",
              " 'ieerstr2tree',\n",
              " 'improved_close_quote_regex',\n",
              " 'improved_open_quote_regex',\n",
              " 'improved_punct_regex',\n",
              " 'in_idle',\n",
              " 'induce_pcfg',\n",
              " 'inference',\n",
              " 'infile',\n",
              " 'inspect',\n",
              " 'install_opener',\n",
              " 'internals',\n",
              " 'interpret_sents',\n",
              " 'interval_distance',\n",
              " 'invert_dict',\n",
              " 'invert_graph',\n",
              " 'is_rel',\n",
              " 'islice',\n",
              " 'isri',\n",
              " 'jaccard_distance',\n",
              " 'json_tags',\n",
              " 'jsontags',\n",
              " 'lancaster',\n",
              " 'lazyimport',\n",
              " 'lfg',\n",
              " 'line_tokenize',\n",
              " 'linearlogic',\n",
              " 'load',\n",
              " 'load_parser',\n",
              " 'locale',\n",
              " 'log_likelihood',\n",
              " 'logic',\n",
              " 'mace',\n",
              " 'malt',\n",
              " 'map_tag',\n",
              " 'mapping',\n",
              " 'masi_distance',\n",
              " 'maxent',\n",
              " 'megam',\n",
              " 'memoize',\n",
              " 'metrics',\n",
              " 'misc',\n",
              " 'mwe',\n",
              " 'naivebayes',\n",
              " 'ne_chunk',\n",
              " 'ne_chunk_sents',\n",
              " 'ngrams',\n",
              " 'nonprojectivedependencyparser',\n",
              " 'nonterminals',\n",
              " 'numpy',\n",
              " 'os',\n",
              " 'pad_sequence',\n",
              " 'paice',\n",
              " 'parse',\n",
              " 'parse_sents',\n",
              " 'pchart',\n",
              " 'perceptron',\n",
              " 'pk',\n",
              " 'porter',\n",
              " 'pos_tag',\n",
              " 'pos_tag_sents',\n",
              " 'positivenaivebayes',\n",
              " 'pprint',\n",
              " 'pr',\n",
              " 'precision',\n",
              " 'presence',\n",
              " 'print_function',\n",
              " 'print_string',\n",
              " 'probability',\n",
              " 'projectivedependencyparser',\n",
              " 'prover9',\n",
              " 'punkt',\n",
              " 'py25',\n",
              " 'py26',\n",
              " 'py27',\n",
              " 'pydoc',\n",
              " 'python_2_unicode_compatible',\n",
              " 'raise_unorderable_types',\n",
              " 'ranks_from_scores',\n",
              " 'ranks_from_sequence',\n",
              " 're',\n",
              " 're_show',\n",
              " 'read_grammar',\n",
              " 'read_logic',\n",
              " 'read_valuation',\n",
              " 'recall',\n",
              " 'recursivedescent',\n",
              " 'regexp',\n",
              " 'regexp_span_tokenize',\n",
              " 'regexp_tokenize',\n",
              " 'register_tag',\n",
              " 'relextract',\n",
              " 'repp',\n",
              " 'resolution',\n",
              " 'ribes',\n",
              " 'ribes_score',\n",
              " 'root_semrep',\n",
              " 'rslp',\n",
              " 'rte_classifier',\n",
              " 'rte_classify',\n",
              " 'rte_features',\n",
              " 'rtuple',\n",
              " 'scikitlearn',\n",
              " 'scores',\n",
              " 'segmentation',\n",
              " 'sem',\n",
              " 'senna',\n",
              " 'sent_tokenize',\n",
              " 'sequential',\n",
              " 'set2rel',\n",
              " 'set_proxy',\n",
              " 'sexpr',\n",
              " 'sexpr_tokenize',\n",
              " 'shiftreduce',\n",
              " 'simple',\n",
              " 'sinica_parse',\n",
              " 'skipgrams',\n",
              " 'skolemize',\n",
              " 'slice_bounds',\n",
              " 'snowball',\n",
              " 'spearman',\n",
              " 'spearman_correlation',\n",
              " 'stack_decoder',\n",
              " 'stanford',\n",
              " 'stanford_segmenter',\n",
              " 'stem',\n",
              " 'str2tuple',\n",
              " 'string_span_tokenize',\n",
              " 'string_types',\n",
              " 'subprocess',\n",
              " 'subsumes',\n",
              " 'sum_logs',\n",
              " 'sys',\n",
              " 'tableau',\n",
              " 'tadm',\n",
              " 'tag',\n",
              " 'tagset_mapping',\n",
              " 'tagstr2tree',\n",
              " 'tbl',\n",
              " 'text',\n",
              " 'text_type',\n",
              " 'textcat',\n",
              " 'texttiling',\n",
              " 'textwrap',\n",
              " 'tkinter',\n",
              " 'tnt',\n",
              " 'tokenize',\n",
              " 'tokenwrap',\n",
              " 'toktok',\n",
              " 'toolbox',\n",
              " 'total_ordering',\n",
              " 'transitionparser',\n",
              " 'transitive_closure',\n",
              " 'translate',\n",
              " 'tree',\n",
              " 'tree2conllstr',\n",
              " 'tree2conlltags',\n",
              " 'treebank',\n",
              " 'treetransforms',\n",
              " 'trigrams',\n",
              " 'tuple2str',\n",
              " 'types',\n",
              " 'unify',\n",
              " 'unique_list',\n",
              " 'untag',\n",
              " 'usage',\n",
              " 'util',\n",
              " 'version_file',\n",
              " 'version_info',\n",
              " 'viterbi',\n",
              " 'weka',\n",
              " 'windowdiff',\n",
              " 'word_tokenize',\n",
              " 'wordnet',\n",
              " 'wordpunct_tokenize',\n",
              " 'wsd']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfkaXVTg2hVC",
        "outputId": "e6a3d0d2-abcf-46d3-bc25-ce1e84a71902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "Review_data = pd.read_csv(\"./docreview2.csv\",engine=\"python\")\n",
        "Review_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Doctor</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jarrad A. Merriman| MD| MPH</td>\n",
              "      <td>�Dr. Merriman is very nice and explained every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jaime D. Hernandez| MD</td>\n",
              "      <td>�Total hip replacement: I can't believe how we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain did surgery on my lower lumbar. I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Indeed| the most treasured of the Doctors I h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain was a kind| competent| and excellent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>Brian S. Grossman| MD</td>\n",
              "      <td>�Dr. Grossman is the best doctor. If you have ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>Fadi S. Saied| DO</td>\n",
              "      <td>�Friendly| efficient| thorough staff and Doctor.�</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>Jonathan Falakassa| MD</td>\n",
              "      <td>�Did two epidurals that were not helpful. Refe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>Brian S. Grossman| MD</td>\n",
              "      <td>�very positive| was seen in a timely manner an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>Kamil Erfanian| MD</td>\n",
              "      <td>�It was fine. No procedure| just information f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>678 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Doctor                                             Review\n",
              "0    Jarrad A. Merriman| MD| MPH  �Dr. Merriman is very nice and explained every...\n",
              "1         Jaime D. Hernandez| MD  �Total hip replacement: I can't believe how we...\n",
              "2             Nickul S. Jain| MD  �Dr. Jain did surgery on my lower lumbar. I am...\n",
              "3             Nickul S. Jain| MD  �Indeed| the most treasured of the Doctors I h...\n",
              "4             Nickul S. Jain| MD  �Dr. Jain was a kind| competent| and excellent...\n",
              "..                           ...                                                ...\n",
              "673        Brian S. Grossman| MD  �Dr. Grossman is the best doctor. If you have ...\n",
              "674           Fadi S. Saied| DO   �Friendly| efficient| thorough staff and Doctor.�\n",
              "675       Jonathan Falakassa| MD  �Did two epidurals that were not helpful. Refe...\n",
              "676        Brian S. Grossman| MD  �very positive| was seen in a timely manner an...\n",
              "677           Kamil Erfanian| MD  �It was fine. No procedure| just information f...\n",
              "\n",
              "[678 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Lv3q0z_MTU"
      },
      "source": [
        "Review_data1 = pd.read_csv(\"./docreview4.csv\",engine=\"python\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8_zxM77_Ljk"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4IggKyv-zJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z24AiUEv_Es",
        "outputId": "5c09b36b-7016-485b-ecec-368f78dd7da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "Review_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Doctor</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jarrad A. Merriman| MD| MPH</td>\n",
              "      <td>�Dr. Merriman is very nice and explained every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jaime D. Hernandez| MD</td>\n",
              "      <td>�Total hip replacement: I can't believe how we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain did surgery on my lower lumbar. I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Indeed| the most treasured of the Doctors I h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain was a kind| competent| and excellent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Doctor                                             Review\n",
              "0  Jarrad A. Merriman| MD| MPH  �Dr. Merriman is very nice and explained every...\n",
              "1       Jaime D. Hernandez| MD  �Total hip replacement: I can't believe how we...\n",
              "2           Nickul S. Jain| MD  �Dr. Jain did surgery on my lower lumbar. I am...\n",
              "3           Nickul S. Jain| MD  �Indeed| the most treasured of the Doctors I h...\n",
              "4           Nickul S. Jain| MD  �Dr. Jain was a kind| competent| and excellent..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM5oW1wR-HrH",
        "outputId": "d26a3369-60ee-4ae3-c42b-775e2164d0b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(Review_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2EQc9ss_BRc"
      },
      "source": [
        "Reviews_doc = Review_data.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJBoFR9a_b4M"
      },
      "source": [
        "TOTAL_DATASETS = Review_data.append(Review_data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9tzWyrd_ioc",
        "outputId": "e30c72f8-8bce-4ade-df96-23273d15c94d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "TOTAL_DATASETS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Doctor</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jarrad A. Merriman| MD| MPH</td>\n",
              "      <td>�Dr. Merriman is very nice and explained every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jaime D. Hernandez| MD</td>\n",
              "      <td>�Total hip replacement: I can't believe how we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain did surgery on my lower lumbar. I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Indeed| the most treasured of the Doctors I h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nickul S. Jain| MD</td>\n",
              "      <td>�Dr. Jain was a kind| competent| and excellent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Thomas E. Dudley| M.D.| Ph.D.</td>\n",
              "      <td>�\"The folks at Heartland Orthopedics were abso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>Russell S. Sticha| D.P.M.</td>\n",
              "      <td>�\"Everyone seemed very competent at my first v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Paul A. Dale| M.D.</td>\n",
              "      <td>�\"I find the doctor that did my knee replaceme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>Dennis P. Weigel| M.D.</td>\n",
              "      <td>�\"I would like to thank Dr. Dennis Weigel for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>Paul A. Dale| M.D.</td>\n",
              "      <td>�\"Dr. Dale is excellent| but then the whole st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>787 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Doctor                                             Review\n",
              "0      Jarrad A. Merriman| MD| MPH  �Dr. Merriman is very nice and explained every...\n",
              "1           Jaime D. Hernandez| MD  �Total hip replacement: I can't believe how we...\n",
              "2               Nickul S. Jain| MD  �Dr. Jain did surgery on my lower lumbar. I am...\n",
              "3               Nickul S. Jain| MD  �Indeed| the most treasured of the Doctors I h...\n",
              "4               Nickul S. Jain| MD  �Dr. Jain was a kind| competent| and excellent...\n",
              "..                             ...                                                ...\n",
              "104  Thomas E. Dudley| M.D.| Ph.D.  �\"The folks at Heartland Orthopedics were abso...\n",
              "105      Russell S. Sticha| D.P.M.  �\"Everyone seemed very competent at my first v...\n",
              "106             Paul A. Dale| M.D.  �\"I find the doctor that did my knee replaceme...\n",
              "107         Dennis P. Weigel| M.D.  �\"I would like to thank Dr. Dennis Weigel for ...\n",
              "108             Paul A. Dale| M.D.  �\"Dr. Dale is excellent| but then the whole st...\n",
              "\n",
              "[787 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0s9d5BL_lPj"
      },
      "source": [
        "TOTAL_DATASETS.to_csv('file1.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VujGkLg5AtxU",
        "outputId": "1358142b-5128-4953-9016-d14524692362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TOTAL_DATASETS.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      �Dr. Merriman is very nice and explained every...\n",
              "1      �Total hip replacement: I can't believe how we...\n",
              "2      �Dr. Jain did surgery on my lower lumbar. I am...\n",
              "3      �Indeed| the most treasured of the Doctors I h...\n",
              "4      �Dr. Jain was a kind| competent| and excellent...\n",
              "                             ...                        \n",
              "104    �\"The folks at Heartland Orthopedics were abso...\n",
              "105    �\"Everyone seemed very competent at my first v...\n",
              "106    �\"I find the doctor that did my knee replaceme...\n",
              "107    �\"I would like to thank Dr. Dennis Weigel for ...\n",
              "108    �\"Dr. Dale is excellent| but then the whole st...\n",
              "Name: Review, Length: 787, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz-CKnu-BOMS"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9eoRxNuFdGy",
        "outputId": "a875315a-1ca1-4449-fac2-fdd07b0e8095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> l\n",
            "\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "Hit Enter to continue: \n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "Hit Enter to continue: all\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "Hit Enter to continue: \n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "Hit Enter to continue: all\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: book_grammars\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataserver, use_threads)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0;31m# Create the main window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+50+50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-6e230a00a763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_simple_interactive_download\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     self._ds.list(self._ds.download_dir, header=False,\n\u001b[0;32m-> 1047\u001b[0;31m                                   more_prompt=True, skip_installed=True)\n\u001b[0m\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, download_dir, show_packages, show_collections, header, more_prompt, skip_installed)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for more_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmore_prompt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hit Enter to continue: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLcgHM7cC9Mb",
        "outputId": "80bf1816-cf52-4d5e-98c5-e1898c4798db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "REVIEW_ONE = TOTAL_DATASETS.iloc[4,-1]\n",
        "REVIEW_ONE=REVIEW_ONE[1:-2]\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RGs0Tc_E5ti",
        "outputId": "92aaf043-c2da-46db-f54b-3244558f4e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(REVIEW_ONE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDDHFWUUElv6",
        "outputId": "aa1984aa-a829-4902-8ddc-96b16874cc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(word_tokenize(REVIEW_ONE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Dr.', 'Jain', 'was', 'a', 'kind|', 'competent|', 'and', 'excellent', 'diagnostician', '.', 'He', 'sent', 'me', 'to', 'Dr.', 'Blose', '.', 'She', 'is', 'superior', 'to', 'check', 'my', 'neck|', 'which', 'none', 'of', 'the', 'other', 'orthopedic', 'Doctors', 'has', 'done', '.', 'I', 'have', 'a', 'pinched', 'nerve', 'in', 'my', 'neck', '.', 'Dr.', 'Jain', 'gave', 'me', 'hope', 'when', 'I', 'had', 'given', 'up', 'on', 'getting', 'relief', 'from', 'my', 'back', 'pain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh7SF7P9IO1L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjzo9gevHy05",
        "outputId": "a012cf0f-9064-468a-8ecd-a07b627b376d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3043129 sha256=6b97355b142bcf1b416aa108b311ebb03dcfe589e6b8474967a974b942431636\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Wy3arBIF2w"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7cKsVS9IPoB",
        "outputId": "adc861a7-3c92-4877-cdcc-6f4d0253cd4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dir(fasttext)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BOW',\n",
              " 'EOS',\n",
              " 'EOW',\n",
              " 'FastText',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'absolute_import',\n",
              " 'cbow',\n",
              " 'division',\n",
              " 'load_model',\n",
              " 'print_function',\n",
              " 'skipgram',\n",
              " 'supervised',\n",
              " 'tokenize',\n",
              " 'train_supervised',\n",
              " 'train_unsupervised',\n",
              " 'unicode_literals']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0SL7KwJIS3B"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNZZ7s-PIado",
        "outputId": "a0c301e9-2b55-4677-ac6a-f2ec09338439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TRAIN_DATASET = TOTAL_DATASETS[:500]\n",
        "TRAIN_DATASET.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEd1dfUI8vA"
      },
      "source": [
        "TEST_DATASET = TOTAL_DATASETS[500:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI2zyBybJBFh",
        "outputId": "cfcc552e-5e79-4709-9912-0e56fcd96523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model = fasttext.train_supervised(input=TRAIN_DATASET)\n",
        "kk=[]\n",
        "# for i in range(len(TRAIN_DATASET)):\n",
        "#   TRAIN_DATASET.iloc[i]\n",
        "str(TRAIN_DATASET.iloc[i])\n",
        "type(TRAIN_DATASET.iloc[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qct9I6CgLRCi",
        "outputId": "80a131e9-4061-4025-b9af-a0e2e6410f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Doctor', 'Review']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpmNQs5WNGHp",
        "outputId": "75776889-c557-48b9-f731-d2996a5a6271",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import fasttext.util\n",
        "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uiQgQVnUBnb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1VJmwPTUCoF"
      },
      "source": [
        "NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKyyzc6vUEe9",
        "outputId": "b6d5289d-aa29-4eb0-f61a-888377e06e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4tB2FQSUHX9"
      },
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "import random\n",
        "\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "              for category in movie_reviews.categories()\n",
        "              for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IKr7AAFUKwV"
      },
      "source": [
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV_bhnSeUQ9c"
      },
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UVjo3cxX5qd"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S7pDjFCX-mg",
        "outputId": "d0df0d67-c92b-4d2e-a18e-d8cdfcca3911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3DEUUUxYC5b",
        "outputId": "6ab2e1bc-f699-436f-d9b1-0be581a65c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(word_tokenize(REVIEW_ONE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Dr.', 'Jain', 'was', 'a', 'kind|', 'competent|', 'and', 'excellent', 'diagnostician', '.', 'He', 'sent', 'me', 'to', 'Dr.', 'Blose', '.', 'She', 'is', 'superior', 'to', 'check', 'my', 'neck|', 'which', 'none', 'of', 'the', 'other', 'orthopedic', 'Doctors', 'has', 'done', '.', 'I', 'have', 'a', 'pinched', 'nerve', 'in', 'my', 'neck', '.', 'Dr.', 'Jain', 'gave', 'me', 'hope', 'when', 'I', 'had', 'given', 'up', 'on', 'getting', 'relief', 'from', 'my', 'back', 'pain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQu81w7SYEFb"
      },
      "source": [
        "words_data= list(test_set[30][0].keys())\n",
        "result_data= list(test_set[30][0].values())\n",
        "\n",
        "l=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuH82uFJlV_Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv_LNQati_gc"
      },
      "source": [
        "for i in words_data:\n",
        "  l.append(i[9:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYw9Wi1Zjj-A"
      },
      "source": [
        "ll=[]\n",
        "for i in result_data:\n",
        "  ll.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4RdZA5dnmQI",
        "outputId": "d33ab41f-bc76-43e8-f580-a11966d32f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ll"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oExM2uoHj5FY",
        "outputId": "0b16ec74-035a-48f0-d3cf-f1f8ba4e0022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_set[33][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmiC8-K1jL-4",
        "outputId": "c11b1944-cf12-4c92-84f2-3f5f6edcdf50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot',\n",
              " ':',\n",
              " 'two',\n",
              " 'teen',\n",
              " 'couples',\n",
              " 'go',\n",
              " 'to',\n",
              " 'a',\n",
              " 'church',\n",
              " 'party',\n",
              " ',',\n",
              " 'drink',\n",
              " 'and',\n",
              " 'then',\n",
              " 'drive',\n",
              " '.',\n",
              " 'they',\n",
              " 'get',\n",
              " 'into',\n",
              " 'an',\n",
              " 'accident',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'guys',\n",
              " 'dies',\n",
              " 'but',\n",
              " 'his',\n",
              " 'girlfriend',\n",
              " 'continues',\n",
              " 'see',\n",
              " 'him',\n",
              " 'in',\n",
              " 'her',\n",
              " 'life',\n",
              " 'has',\n",
              " 'nightmares',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'deal',\n",
              " '?',\n",
              " 'watch',\n",
              " 'movie',\n",
              " '\"',\n",
              " 'sorta',\n",
              " 'find',\n",
              " 'out',\n",
              " 'critique',\n",
              " 'mind',\n",
              " '-',\n",
              " 'fuck',\n",
              " 'for',\n",
              " 'generation',\n",
              " 'that',\n",
              " 'touches',\n",
              " 'on',\n",
              " 'very',\n",
              " 'cool',\n",
              " 'idea',\n",
              " 'presents',\n",
              " 'it',\n",
              " 'bad',\n",
              " 'package',\n",
              " 'which',\n",
              " 'is',\n",
              " 'makes',\n",
              " 'this',\n",
              " 'review',\n",
              " 'even',\n",
              " 'harder',\n",
              " 'write',\n",
              " 'since',\n",
              " 'i',\n",
              " 'generally',\n",
              " 'applaud',\n",
              " 'films',\n",
              " 'attempt',\n",
              " 'break',\n",
              " 'mold',\n",
              " 'mess',\n",
              " 'with',\n",
              " 'your',\n",
              " 'head',\n",
              " 'such',\n",
              " '(',\n",
              " 'lost',\n",
              " 'highway',\n",
              " '&',\n",
              " 'memento',\n",
              " ')',\n",
              " 'there',\n",
              " 'are',\n",
              " 'good',\n",
              " 'ways',\n",
              " 'making',\n",
              " 'all',\n",
              " 'types',\n",
              " 'these',\n",
              " 'folks',\n",
              " 'just',\n",
              " 'didn',\n",
              " 't',\n",
              " 'snag',\n",
              " 'correctly',\n",
              " 'seem',\n",
              " 'have',\n",
              " 'taken',\n",
              " 'pretty',\n",
              " 'neat',\n",
              " 'concept',\n",
              " 'executed',\n",
              " 'terribly',\n",
              " 'so',\n",
              " 'problems',\n",
              " 'well',\n",
              " 'its',\n",
              " 'main',\n",
              " 'problem',\n",
              " 'simply',\n",
              " 'too',\n",
              " 'jumbled',\n",
              " 'starts',\n",
              " 'off',\n",
              " 'normal',\n",
              " 'downshifts',\n",
              " 'fantasy',\n",
              " 'world',\n",
              " 'you',\n",
              " 'as',\n",
              " 'audience',\n",
              " 'member',\n",
              " 'no',\n",
              " 'going',\n",
              " 'dreams',\n",
              " 'characters',\n",
              " 'coming',\n",
              " 'back',\n",
              " 'from',\n",
              " 'dead',\n",
              " 'others',\n",
              " 'who',\n",
              " 'look',\n",
              " 'like',\n",
              " 'strange',\n",
              " 'apparitions',\n",
              " 'disappearances',\n",
              " 'looooot',\n",
              " 'chase',\n",
              " 'scenes',\n",
              " 'tons',\n",
              " 'weird',\n",
              " 'things',\n",
              " 'happen',\n",
              " 'most',\n",
              " 'not',\n",
              " 'explained',\n",
              " 'now',\n",
              " 'personally',\n",
              " 'don',\n",
              " 'trying',\n",
              " 'unravel',\n",
              " 'film',\n",
              " 'every',\n",
              " 'when',\n",
              " 'does',\n",
              " 'give',\n",
              " 'me',\n",
              " 'same',\n",
              " 'clue',\n",
              " 'over',\n",
              " 'again',\n",
              " 'kind',\n",
              " 'fed',\n",
              " 'up',\n",
              " 'after',\n",
              " 'while',\n",
              " 'biggest',\n",
              " 'obviously',\n",
              " 'got',\n",
              " 'big',\n",
              " 'secret',\n",
              " 'hide',\n",
              " 'seems',\n",
              " 'want',\n",
              " 'completely',\n",
              " 'until',\n",
              " 'final',\n",
              " 'five',\n",
              " 'minutes',\n",
              " 'do',\n",
              " 'make',\n",
              " 'entertaining',\n",
              " 'thrilling',\n",
              " 'or',\n",
              " 'engaging',\n",
              " 'meantime',\n",
              " 'really',\n",
              " 'sad',\n",
              " 'part',\n",
              " 'arrow',\n",
              " 'both',\n",
              " 'dig',\n",
              " 'flicks',\n",
              " 'we',\n",
              " 'actually',\n",
              " 'figured',\n",
              " 'by',\n",
              " 'half',\n",
              " 'way',\n",
              " 'point',\n",
              " 'strangeness',\n",
              " 'did',\n",
              " 'start',\n",
              " 'little',\n",
              " 'bit',\n",
              " 'sense',\n",
              " 'still',\n",
              " 'more',\n",
              " 'guess',\n",
              " 'bottom',\n",
              " 'line',\n",
              " 'movies',\n",
              " 'should',\n",
              " 'always',\n",
              " 'sure',\n",
              " 'before',\n",
              " 'given',\n",
              " 'password',\n",
              " 'enter',\n",
              " 'understanding',\n",
              " 'mean',\n",
              " 'showing',\n",
              " 'melissa',\n",
              " 'sagemiller',\n",
              " 'running',\n",
              " 'away',\n",
              " 'visions',\n",
              " 'about',\n",
              " '20',\n",
              " 'throughout',\n",
              " 'plain',\n",
              " 'lazy',\n",
              " '!',\n",
              " 'okay',\n",
              " 'people',\n",
              " 'chasing',\n",
              " 'know',\n",
              " 'need',\n",
              " 'how',\n",
              " 'giving',\n",
              " 'us',\n",
              " 'different',\n",
              " 'offering',\n",
              " 'further',\n",
              " 'insight',\n",
              " 'down',\n",
              " 'apparently',\n",
              " 'studio',\n",
              " 'took',\n",
              " 'director',\n",
              " 'chopped',\n",
              " 'themselves',\n",
              " 'shows',\n",
              " 'might',\n",
              " 've',\n",
              " 'been',\n",
              " 'decent',\n",
              " 'here',\n",
              " 'somewhere',\n",
              " 'suits',\n",
              " 'decided',\n",
              " 'turning',\n",
              " 'music',\n",
              " 'video',\n",
              " 'edge',\n",
              " 'would',\n",
              " 'actors',\n",
              " 'although',\n",
              " 'wes',\n",
              " 'bentley',\n",
              " 'seemed',\n",
              " 'be',\n",
              " 'playing',\n",
              " 'exact',\n",
              " 'character',\n",
              " 'he',\n",
              " 'american',\n",
              " 'beauty',\n",
              " 'only',\n",
              " 'new',\n",
              " 'neighborhood',\n",
              " 'my',\n",
              " 'kudos',\n",
              " 'holds',\n",
              " 'own',\n",
              " 'entire',\n",
              " 'feeling',\n",
              " 'unraveling',\n",
              " 'overall',\n",
              " 'doesn',\n",
              " 'stick',\n",
              " 'because',\n",
              " 'entertain',\n",
              " 'confusing',\n",
              " 'rarely',\n",
              " 'excites',\n",
              " 'feels',\n",
              " 'redundant',\n",
              " 'runtime',\n",
              " 'despite',\n",
              " 'ending',\n",
              " 'explanation',\n",
              " 'craziness',\n",
              " 'came',\n",
              " 'oh',\n",
              " 'horror',\n",
              " 'slasher',\n",
              " 'flick',\n",
              " 'packaged',\n",
              " 'someone',\n",
              " 'assuming',\n",
              " 'genre',\n",
              " 'hot',\n",
              " 'kids',\n",
              " 'also',\n",
              " 'wrapped',\n",
              " 'production',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'sitting',\n",
              " 'shelves',\n",
              " 'ever',\n",
              " 'whatever',\n",
              " 'skip',\n",
              " 'where',\n",
              " 'joblo',\n",
              " 'nightmare',\n",
              " 'elm',\n",
              " 'street',\n",
              " '3',\n",
              " '7',\n",
              " '/',\n",
              " '10',\n",
              " 'blair',\n",
              " 'witch',\n",
              " '2',\n",
              " 'crow',\n",
              " '9',\n",
              " 'salvation',\n",
              " '4',\n",
              " 'stir',\n",
              " 'echoes',\n",
              " '8',\n",
              " 'happy',\n",
              " 'bastard',\n",
              " 'quick',\n",
              " 'damn',\n",
              " 'y2k',\n",
              " 'bug',\n",
              " 'starring',\n",
              " 'jamie',\n",
              " 'lee',\n",
              " 'curtis',\n",
              " 'another',\n",
              " 'baldwin',\n",
              " 'brother',\n",
              " 'william',\n",
              " 'time',\n",
              " 'story',\n",
              " 'regarding',\n",
              " 'crew',\n",
              " 'tugboat',\n",
              " 'comes',\n",
              " 'across',\n",
              " 'deserted',\n",
              " 'russian',\n",
              " 'tech',\n",
              " 'ship',\n",
              " 'kick',\n",
              " 'power',\n",
              " 'within',\n",
              " 'gore',\n",
              " 'bringing',\n",
              " 'few',\n",
              " 'action',\n",
              " 'sequences',\n",
              " 'virus',\n",
              " 'empty',\n",
              " 'flash',\n",
              " 'substance',\n",
              " 'why',\n",
              " 'was',\n",
              " 'middle',\n",
              " 'nowhere',\n",
              " 'origin',\n",
              " 'pink',\n",
              " 'flashy',\n",
              " 'thing',\n",
              " 'hit',\n",
              " 'mir',\n",
              " 'course',\n",
              " 'donald',\n",
              " 'sutherland',\n",
              " 'stumbling',\n",
              " 'around',\n",
              " 'drunkenly',\n",
              " 'hey',\n",
              " 'let',\n",
              " 'some',\n",
              " 'robots',\n",
              " 'acting',\n",
              " 'below',\n",
              " 'average',\n",
              " 'likes',\n",
              " 're',\n",
              " 'likely',\n",
              " 'work',\n",
              " 'halloween',\n",
              " 'h20',\n",
              " 'wasted',\n",
              " 'real',\n",
              " 'star',\n",
              " 'stan',\n",
              " 'winston',\n",
              " 'robot',\n",
              " 'design',\n",
              " 'schnazzy',\n",
              " 'cgi',\n",
              " 'occasional',\n",
              " 'shot',\n",
              " 'picking',\n",
              " 'brain',\n",
              " 'if',\n",
              " 'body',\n",
              " 'parts',\n",
              " 'turn',\n",
              " 'otherwise',\n",
              " 'much',\n",
              " 'sunken',\n",
              " 'jaded',\n",
              " 'viewer',\n",
              " 'thankful',\n",
              " 'invention',\n",
              " 'timex',\n",
              " 'indiglo',\n",
              " 'based',\n",
              " 'late',\n",
              " '1960',\n",
              " 'television',\n",
              " 'show',\n",
              " 'name',\n",
              " 'mod',\n",
              " 'squad',\n",
              " 'tells',\n",
              " 'tale',\n",
              " 'three',\n",
              " 'reformed',\n",
              " 'criminals',\n",
              " 'under',\n",
              " 'employ',\n",
              " 'police',\n",
              " 'undercover',\n",
              " 'however',\n",
              " 'wrong',\n",
              " 'evidence',\n",
              " 'gets',\n",
              " 'stolen',\n",
              " 'immediately',\n",
              " 'suspicion',\n",
              " 'ads',\n",
              " 'cuts',\n",
              " 'claire',\n",
              " 'dane',\n",
              " 'nice',\n",
              " 'hair',\n",
              " 'cute',\n",
              " 'outfits',\n",
              " 'car',\n",
              " 'chases',\n",
              " 'stuff',\n",
              " 'blowing',\n",
              " 'sounds',\n",
              " 'first',\n",
              " 'fifteen',\n",
              " 'quickly',\n",
              " 'becomes',\n",
              " 'apparent',\n",
              " 'certainly',\n",
              " 'slick',\n",
              " 'looking',\n",
              " 'complete',\n",
              " 'costumes',\n",
              " 'isn',\n",
              " 'enough',\n",
              " 'best',\n",
              " 'described',\n",
              " 'cross',\n",
              " 'between',\n",
              " 'hour',\n",
              " 'long',\n",
              " 'cop',\n",
              " 'stretched',\n",
              " 'span',\n",
              " 'single',\n",
              " 'clich',\n",
              " 'matter',\n",
              " 'elements',\n",
              " 'recycled',\n",
              " 'everything',\n",
              " 'already',\n",
              " 'seen',\n",
              " 'nothing',\n",
              " 'spectacular',\n",
              " 'sometimes',\n",
              " 'bordering',\n",
              " 'wooden',\n",
              " 'danes',\n",
              " 'omar',\n",
              " 'epps',\n",
              " 'deliver',\n",
              " 'their',\n",
              " 'lines',\n",
              " 'bored',\n",
              " 'transfers',\n",
              " 'onto',\n",
              " 'escape',\n",
              " 'relatively',\n",
              " 'unscathed',\n",
              " 'giovanni',\n",
              " 'ribisi',\n",
              " 'plays',\n",
              " 'resident',\n",
              " 'crazy',\n",
              " 'man',\n",
              " 'ultimately',\n",
              " 'being',\n",
              " 'worth',\n",
              " 'watching',\n",
              " 'unfortunately',\n",
              " 'save',\n",
              " 'convoluted',\n",
              " 'apart',\n",
              " 'occupying',\n",
              " 'screen',\n",
              " 'young',\n",
              " 'cast',\n",
              " 'clothes',\n",
              " 'hip',\n",
              " 'soundtrack',\n",
              " 'appears',\n",
              " 'geared',\n",
              " 'towards',\n",
              " 'teenage',\n",
              " 'mindset',\n",
              " 'r',\n",
              " 'rating',\n",
              " 'content',\n",
              " 'justify',\n",
              " 'juvenile',\n",
              " 'older',\n",
              " 'information',\n",
              " 'literally',\n",
              " 'spoon',\n",
              " 'hard',\n",
              " 'instead',\n",
              " 'telling',\n",
              " 'dialogue',\n",
              " 'poorly',\n",
              " 'written',\n",
              " 'extremely',\n",
              " 'predictable',\n",
              " 'progresses',\n",
              " 'won',\n",
              " 'care',\n",
              " 'heroes',\n",
              " 'any',\n",
              " 'jeopardy',\n",
              " 'll',\n",
              " 'aren',\n",
              " 'basing',\n",
              " 'nobody',\n",
              " 'remembers',\n",
              " 'questionable',\n",
              " 'wisdom',\n",
              " 'especially',\n",
              " 'considers',\n",
              " 'target',\n",
              " 'fact',\n",
              " 'number',\n",
              " 'memorable',\n",
              " 'can',\n",
              " 'counted',\n",
              " 'hand',\n",
              " 'missing',\n",
              " 'finger',\n",
              " 'times',\n",
              " 'checked',\n",
              " 'six',\n",
              " 'clear',\n",
              " 'indication',\n",
              " 'them',\n",
              " 'than',\n",
              " 'cash',\n",
              " 'spending',\n",
              " 'dollar',\n",
              " 'judging',\n",
              " 'rash',\n",
              " 'awful',\n",
              " 'seeing',\n",
              " 'avoid',\n",
              " 'at',\n",
              " 'costs',\n",
              " 'quest',\n",
              " 'camelot',\n",
              " 'warner',\n",
              " 'bros',\n",
              " 'feature',\n",
              " 'length',\n",
              " 'fully',\n",
              " 'animated',\n",
              " 'steal',\n",
              " 'clout',\n",
              " 'disney',\n",
              " 'cartoon',\n",
              " 'empire',\n",
              " 'mouse',\n",
              " 'reason',\n",
              " 'worried',\n",
              " 'other',\n",
              " 'recent',\n",
              " 'challenger',\n",
              " 'throne',\n",
              " 'last',\n",
              " 'fall',\n",
              " 'promising',\n",
              " 'flawed',\n",
              " '20th',\n",
              " 'century',\n",
              " 'fox',\n",
              " 'anastasia',\n",
              " 'hercules',\n",
              " 'lively',\n",
              " 'colorful',\n",
              " 'palate',\n",
              " 'had',\n",
              " 'beat',\n",
              " 'hands',\n",
              " 'crown',\n",
              " '1997',\n",
              " 'piece',\n",
              " 'animation',\n",
              " 'year',\n",
              " 'contest',\n",
              " 'arrival',\n",
              " 'magic',\n",
              " 'kingdom',\n",
              " 'mediocre',\n",
              " '--',\n",
              " 'd',\n",
              " 'pocahontas',\n",
              " 'those',\n",
              " 'keeping',\n",
              " 'score',\n",
              " 'nearly',\n",
              " 'dull',\n",
              " 'revolves',\n",
              " 'adventures',\n",
              " 'free',\n",
              " 'spirited',\n",
              " 'kayley',\n",
              " 'voiced',\n",
              " 'jessalyn',\n",
              " 'gilsig',\n",
              " 'early',\n",
              " 'daughter',\n",
              " 'belated',\n",
              " 'knight',\n",
              " 'king',\n",
              " 'arthur',\n",
              " 'round',\n",
              " 'table',\n",
              " 'dream',\n",
              " 'follow',\n",
              " 'father',\n",
              " 'footsteps',\n",
              " 'she',\n",
              " 'chance',\n",
              " 'evil',\n",
              " 'warlord',\n",
              " 'ruber',\n",
              " 'gary',\n",
              " 'oldman',\n",
              " 'ex',\n",
              " 'gone',\n",
              " 'steals',\n",
              " 'magical',\n",
              " 'sword',\n",
              " 'excalibur',\n",
              " 'accidentally',\n",
              " 'loses',\n",
              " 'dangerous',\n",
              " 'booby',\n",
              " 'trapped',\n",
              " 'forest',\n",
              " 'help',\n",
              " 'hunky',\n",
              " 'blind',\n",
              " 'timberland',\n",
              " 'dweller',\n",
              " 'garrett',\n",
              " 'carey',\n",
              " 'elwes',\n",
              " 'headed',\n",
              " 'dragon',\n",
              " 'eric',\n",
              " 'idle',\n",
              " 'rickles',\n",
              " 'arguing',\n",
              " 'itself',\n",
              " 'able',\n",
              " 'medieval',\n",
              " 'sexist',\n",
              " 'prove',\n",
              " 'fighter',\n",
              " 'side',\n",
              " 'pure',\n",
              " 'showmanship',\n",
              " 'essential',\n",
              " 'element',\n",
              " 'expected',\n",
              " 'climb',\n",
              " 'high',\n",
              " 'ranks',\n",
              " 'differentiates',\n",
              " 'something',\n",
              " 'saturday',\n",
              " 'morning',\n",
              " 'subpar',\n",
              " 'instantly',\n",
              " 'forgettable',\n",
              " 'songs',\n",
              " 'integrated',\n",
              " 'computerized',\n",
              " 'footage',\n",
              " 'compare',\n",
              " 'run',\n",
              " 'angry',\n",
              " 'ogre',\n",
              " 'herc',\n",
              " 'battle',\n",
              " 'hydra',\n",
              " 'rest',\n",
              " 'case',\n",
              " 'stink',\n",
              " 'none',\n",
              " 'remotely',\n",
              " 'interesting',\n",
              " 'race',\n",
              " 'bland',\n",
              " 'end',\n",
              " 'tie',\n",
              " 'win',\n",
              " 'comedy',\n",
              " 'shtick',\n",
              " 'awfully',\n",
              " 'cloying',\n",
              " 'least',\n",
              " 'signs',\n",
              " 'pulse',\n",
              " 'fans',\n",
              " \"-'\",\n",
              " '90s',\n",
              " 'tgif',\n",
              " 'will',\n",
              " 'thrilled',\n",
              " 'jaleel',\n",
              " 'urkel',\n",
              " 'white',\n",
              " 'bronson',\n",
              " 'balki',\n",
              " 'pinchot',\n",
              " 'sharing',\n",
              " 'nicely',\n",
              " 'realized',\n",
              " 'though',\n",
              " 'm',\n",
              " 'loss',\n",
              " 'recall',\n",
              " 'specific',\n",
              " 'providing',\n",
              " 'voice',\n",
              " 'talent',\n",
              " 'enthusiastic',\n",
              " 'paired',\n",
              " 'singers',\n",
              " 'sound',\n",
              " 'musical',\n",
              " 'moments',\n",
              " 'jane',\n",
              " 'seymour',\n",
              " 'celine',\n",
              " 'dion',\n",
              " 'must',\n",
              " 'strain',\n",
              " 'through',\n",
              " 'aside',\n",
              " 'children',\n",
              " 'probably',\n",
              " 'adults',\n",
              " 'grievous',\n",
              " 'error',\n",
              " 'lack',\n",
              " 'personality',\n",
              " 'learn',\n",
              " 'goes',\n",
              " 'synopsis',\n",
              " 'mentally',\n",
              " 'unstable',\n",
              " 'undergoing',\n",
              " 'psychotherapy',\n",
              " 'saves',\n",
              " 'boy',\n",
              " 'potentially',\n",
              " 'fatal',\n",
              " 'falls',\n",
              " 'love',\n",
              " 'mother',\n",
              " 'fledgling',\n",
              " 'restauranteur',\n",
              " 'unsuccessfully',\n",
              " 'attempting',\n",
              " 'gain',\n",
              " 'woman',\n",
              " 'favor',\n",
              " 'takes',\n",
              " 'pictures',\n",
              " 'kills',\n",
              " 'comments',\n",
              " 'stalked',\n",
              " 'yet',\n",
              " 'seemingly',\n",
              " 'endless',\n",
              " 'string',\n",
              " 'spurned',\n",
              " 'psychos',\n",
              " 'getting',\n",
              " 'revenge',\n",
              " 'type',\n",
              " 'stable',\n",
              " 'category',\n",
              " '1990s',\n",
              " 'industry',\n",
              " 'theatrical',\n",
              " 'direct',\n",
              " 'proliferation',\n",
              " 'may',\n",
              " 'due',\n",
              " 'typically',\n",
              " 'inexpensive',\n",
              " 'produce',\n",
              " 'special',\n",
              " 'effects',\n",
              " 'stars',\n",
              " 'serve',\n",
              " 'vehicles',\n",
              " 'nudity',\n",
              " 'allowing',\n",
              " 'frequent',\n",
              " 'night',\n",
              " 'cable',\n",
              " 'wavers',\n",
              " 'slightly',\n",
              " 'norm',\n",
              " 'respect',\n",
              " 'psycho',\n",
              " 'never',\n",
              " 'affair',\n",
              " ';',\n",
              " 'contrary',\n",
              " 'rejected',\n",
              " 'rather',\n",
              " 'lover',\n",
              " 'wife',\n",
              " 'husband',\n",
              " 'entry',\n",
              " 'doomed',\n",
              " 'collect',\n",
              " 'dust',\n",
              " 'viewed',\n",
              " 'midnight',\n",
              " 'provide',\n",
              " 'suspense',\n",
              " 'sets',\n",
              " 'interspersed',\n",
              " 'opening',\n",
              " 'credits',\n",
              " 'instance',\n",
              " 'serious',\n",
              " 'sounding',\n",
              " 'narrator',\n",
              " 'spouts',\n",
              " 'statistics',\n",
              " 'stalkers',\n",
              " 'ponders',\n",
              " 'cause',\n",
              " 'stalk',\n",
              " 'implicitly',\n",
              " 'implied',\n",
              " 'men',\n",
              " 'shown',\n",
              " 'snapshot',\n",
              " 'actor',\n",
              " 'jay',\n",
              " 'underwood',\n",
              " 'states',\n",
              " 'daryl',\n",
              " 'gleason',\n",
              " 'stalker',\n",
              " 'brooke',\n",
              " 'daniels',\n",
              " 'meant',\n",
              " 'called',\n",
              " 'guesswork',\n",
              " 'required',\n",
              " 'proceeds',\n",
              " 'begins',\n",
              " 'obvious',\n",
              " 'sequence',\n",
              " 'contrived',\n",
              " 'quite',\n",
              " 'brings',\n",
              " 'victim',\n",
              " 'together',\n",
              " 'obsesses',\n",
              " 'follows',\n",
              " 'tries',\n",
              " 'woo',\n",
              " 'plans',\n",
              " 'become',\n",
              " 'desperate',\n",
              " 'elaborate',\n",
              " 'include',\n",
              " 'cliche',\n",
              " 'murdered',\n",
              " 'pet',\n",
              " 'require',\n",
              " 'found',\n",
              " 'exception',\n",
              " 'cat',\n",
              " 'shower',\n",
              " 'events',\n",
              " 'lead',\n",
              " 'inevitable',\n",
              " 'showdown',\n",
              " 'survives',\n",
              " 'invariably',\n",
              " 'conclusion',\n",
              " 'turkey',\n",
              " 'uniformly',\n",
              " 'adequate',\n",
              " 'anything',\n",
              " 'home',\n",
              " 'either',\n",
              " 'turns',\n",
              " 'toward',\n",
              " 'melodrama',\n",
              " 'overdoes',\n",
              " 'words',\n",
              " 'manages',\n",
              " 'creepy',\n",
              " 'pass',\n",
              " 'demands',\n",
              " 'maryam',\n",
              " 'abo',\n",
              " 'close',\n",
              " 'played',\n",
              " 'bond',\n",
              " 'chick',\n",
              " 'living',\n",
              " 'daylights',\n",
              " 'equally',\n",
              " 'title',\n",
              " 'ditzy',\n",
              " 'strong',\n",
              " 'independent',\n",
              " 'business',\n",
              " 'owner',\n",
              " 'needs',\n",
              " 'proceed',\n",
              " 'example',\n",
              " 'suspicions',\n",
              " 'ensure',\n",
              " 'use',\n",
              " 'excuse',\n",
              " 'decides',\n",
              " 'return',\n",
              " 'toolbox',\n",
              " 'left',\n",
              " 'place',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW8Z1t8rly13",
        "outputId": "22f09a94-75b5-4c03-b681-043f36952572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "T=0\n",
        "F=0\n",
        "for i in ll:\n",
        "  if str(i) == 'True':\n",
        "    T=T+1\n",
        "  elif str(i)=='False':\n",
        "    F=F+1\n",
        "print(T,F)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145 1855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5qXFOzjmKBw",
        "outputId": "44cecd8d-b1e6-49d9-df47-5df8b6af998b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_set[35][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}